AI Vibes, Real Threats: Adversarial ML and LLM Red Teaming

Key Angles:
- Prompt injection, data poisoning, model inversion
- LLM-assisted phishing and social engineering
- Detecting LLM misuse through NetFlow, eBPF hooks, and behavioral telemetry
- AI security baselines (e.g., OWASP Top 10 for LLMs)
